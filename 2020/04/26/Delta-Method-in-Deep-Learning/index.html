<!DOCTYPE html>
<html lang="en">
    <!-- title -->




<!-- keywords -->




<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="Lingfeng Zhu">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Lingfeng Zhu">
    
    <meta name="keywords" content="machine learning,deep learning,recommender system">
    
    <meta name="description" content="">
    <meta name="description" content="This article is the Final project for STAT 732. I summarized the major results and main contributions of a recent statistical paper (published 2019) named On the Delta Method for Uncertainty Approx">
<meta property="og:type" content="article">
<meta property="og:title" content="Delta Method in Deep Learning">
<meta property="og:url" content="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/index.html">
<meta property="og:site_name" content="Vinn&#39;s Studio">
<meta property="og:description" content="This article is the Final project for STAT 732. I summarized the major results and main contributions of a recent statistical paper (published 2019) named On the Delta Method for Uncertainty Approx">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://lingfengzhu.github.io/images/Delta-Method-in-Deep-Learning/flow.jpg">
<meta property="og:image" content="https://lingfengzhu.github.io/images/Delta-Method-in-Deep-Learning/spectrum.jpg">
<meta property="article:published_time" content="2020-04-26T07:19:17.000Z">
<meta property="article:modified_time" content="2021-09-18T06:47:05.635Z">
<meta property="article:author" content="Lingfeng Zhu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lingfengzhu.github.io/images/Delta-Method-in-Deep-Learning/flow.jpg">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    
    <title>Delta Method in Deep Learning · Vinn&#39;s Studio</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/assets/favicon.ico" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

    
        <body class="post-body">
    
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Vinn&#39;s Studio</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Delta Method in Deep Learning</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Vinn's Studio</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(https://source.unsplash.com/random)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Delta Method in Deep Learning
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">1.9k</span>Reading time: <span class="post-count reading-time">11 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2020/04/26</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <script type="text/javascript"
  src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<p><link rel="dns-prefetch" href="//cdn.bootcss.com" /></p>
<p>This article is the Final project for STAT 732. I summarized the major results and main contributions of a recent statistical <a href="https://arxiv.org/abs/1912.00832" target="_blank" rel="noopener">paper</a> (published 2019) named <strong>On the Delta Method for Uncertainty Approximation in Deep Learning</strong>, which utilizes large sample statistical theory in deep learning field and has significant future research potential.</p>
<a id="more"></a>
##
<center>
Introduction
</center>
<hr />
<p>This paper proposes a low cost approximation to the well-known Delta method based on an approximate eigendecomposition of the positive curvature subspace of the Hessian matrix and shows that reasonable uncertainty approximations can be obtained even when the number of utilized Hessian eigenpairs is much lower than the number of model parameters.</p>
##
<center>
Deep Learning Definitions
</center>
<hr />
<h3 id="the-architecture">The Architecture</h3>
<p>The paper uses a feed-forward neural network architecture with dense layers to introduce terminology. There are <span class="math inline">\(L\)</span> layers <span class="math inline">\(l = 1,2,...,L\)</span> with <span class="math inline">\(T_l\)</span> neurons in each layer. The input layer <span class="math inline">\(l = 1\)</span>, is represented by the input vector <span class="math inline">\(x_n=(x_{n,1}, x_{n,2},...,x_{n,T_1})^T\)</span> where <span class="math inline">\(n = 1,2,...,N\)</span> is the input index. Each layer <span class="math inline">\(l\)</span> represented by weight matrices <span class="math inline">\(W^{(l-1)} \in \mathbb{R}^{T_{l} \times T_{l-1}}\)</span>, bias vectors <span class="math inline">\(b^{(l)} \in \mathbb{R}^{T_{l}}\)</span> and vectorized activation functions <span class="math inline">\(\delta^{(l)}\)</span>. The parameter vectors representing the layer-wise weights and biases can be defined as follows, <span class="math display">\[
\omega^{(l)}=\left[\begin{array}{c}
\text { flatten }\left(W^{(l)}\right) \\
b^{(l)}
\end{array}\right]=\left[\omega_{i}^{(l)}\right] \in \mathbb{R}^{P^{(l)}} \tag{1}
\]</span> where <span class="math inline">\(P^{(l)}\)</span> denotes the number of parameters in layer <span class="math inline">\(l\)</span>.</p>
<h3 id="the-model-function">The Model Function</h3>
<p>The architecture has the corresponding model function defined by, <span class="math display">\[
\begin{aligned}
\hat{y}_{n}=&amp; f\left(x_{n}, \omega\right) 
= \sigma^{(L)}\left(W^{(L)} \sigma^{(L-1)}\left(\cdots \sigma^{(2)}\left(W^{(2)} x_{n}\right.\right.\right.
&amp;\left.\left.\left.+b^{(2)}\right)+\cdots\right)+b^{(L)}\right)
\end{aligned} \tag{2}
\]</span></p>
<h3 id="the-cost-function">The Cost Function</h3>
<p>Use softmax cross-entropy with <span class="math inline">\(L_2\)</span>-regularization as the cost function, <span class="math display">\[
\begin{aligned}
C(\omega) &amp;=\frac{1}{N} \sum_{n=1}^{N} C_{n}\left(y_{n}, \hat{y}_{n}\right)+\frac{\lambda}{2} \sum_{p=1}^{P} \omega_{p}^{2} \\
&amp;=\frac{1}{N} \sum_{n=1}^{N}\left(-\sum_{m=1}^{T_{L}} y_{n, m} \log \hat{y}_{n, m}\right)+\frac{\lambda}{2} \sum_{p=1}^{P} \omega_{p}^{2}
\end{aligned} \tag{3}
\]</span> which is the average of <span class="math inline">\(N\)</span> per-example cross-entropy cost functions <span class="math inline">\(C_{n}\left(y_{n}, \hat{y}_{n}\right)\)</span>.</p>
<h3 id="train">Train</h3>
<p>Training of the neural network can be defined as finding an ‘optimal’ parameter vector <span class="math inline">\(\hat{\omega}\)</span> by minimizing the cost function (3).</p>
##
<center>
Delta Method in Deep Learning
</center>
<hr />
<h3 id="the-delta-method">The Delta Method</h3>
<p>The Delta method views a neural network as non-linear regression. By a second-order Taylor expansion, it can be shown that the covariance of the model function (2) can be approximated by, <span class="math display">\[
\operatorname{Cov}\left(f\left(x_{0}, \hat{\omega}\right)\right) \approx F \Sigma F^{T} \in \mathbb{R}^{T_{L} \times T_{L}} \tag{4}
\]</span> where <span class="math display">\[
F=\left[F_{i j}\right] \in \mathbb{R}^{T_{L} \times P}, F_{i j}=\left.\frac{\partial}{\partial \omega_{j}} f_{i}\left(x_{0}, \omega\right)\right|_{\omega=\hat{\omega}} \tag{5}
\]</span> is the Jacobian matrix of the model function, and <span class="math inline">\(\Sigma\)</span> is the covariance matrix of the model parameters. An approximation of the variance associated with the prediction of <span class="math inline">\(x_0\)</span> can thus be found by the formula, <span class="math display">\[
\sigma^{2}\left(x_{0}, \hat{\omega}\right) \approx \operatorname{diag}\left(F \Sigma F^{T}\right) \in \mathbb{R}^{T_{L}} \tag{6}
\]</span></p>
<p>Furthermore, the approximate prediction uncertainty (standard deviation) associated with <span class="math inline">\(x_0\)</span> is defined as <span class="math display">\[
\sigma\left(x_{0}, \hat{\omega}\right)=\sqrt{\sigma^{2}\left(x_{0}, \hat{\omega}\right)} \in \mathbb{R}^{T_{L}} \tag{7}
\]</span> If and only if the parameter vector is a local minimum of the cost function (3), the covariance matrix of the model parameters can be estimated by the Hessian estimator, <span class="math display">\[
\Sigma=\frac{1}{N} H(\hat{\omega})^{-1} \in \mathbb{R}^{P \times P} \tag{8}
\]</span> where <span class="math inline">\(H(\hat{\omega}) \in \mathbb{R}^{P \times P}\)</span> is the Hessian matrix defined by <span class="math display">\[
\left.H(\hat{\omega}) \stackrel{\text { def }}{=} \frac{\partial^{2} C(\omega)}{\partial \omega \partial \omega^{T}}\right|_{\omega=\hat{\omega}}=\left.\frac{1}{N} \sum_{n=1}^{N} \frac{\partial^{2} C_{n}}{\partial \omega \partial \omega^{T}}\right|_{\omega=\hat{\omega}}+\lambda I \tag{9}
\]</span></p>
<h3 id="problems-in-application">Problems in Application</h3>
<p>At this point, we can see that two fundamental difficulties arise when applying the Delta method in deep learning.</p>
<ul>
<li><strong>Problem 1</strong>: The sheer size of the Hessian matrix grows quadratically with <span class="math inline">\(P\)</span>.</li>
<li><strong>Problem 2</strong>: For the inverse of the Hessian matrix to be a valid covariance estimator, the Hessian matrix must be positive definite. That is, we are dependent on that the optimizer can find a true local minimum of the cost function.</li>
</ul>
<h3 id="solving-the-problems">Solving the Problems</h3>
<p>The paper presents its approach to the Delta method in deep learning as a separate process carried out in <strong>two phases</strong> after the neural network has been trained. See <a href="#flow">Figure 1</a> for details.</p>
<div id="flow">
<center>
Figure 1: The Delta method for quantifying the uncertainty in deep learning
</center>
</div>
<p><img src="/images/Delta-Method-in-Deep-Learning/flow.jpg" /></p>
<h4 id="delta-method-initial-phase">Delta Method Initial Phase</h4>
<p>This phase is carried out only once, and is done to compute an indirect approximation of the covariance matrix (8) based on an approximate eigendecomposition of the positive curvature subspace of the Hessian matrix.</p>
<p>In this phase, people can efficiently compute eigenvalues and eigenvectors of the Hessian matrix via the <strong>Lanczos iteration</strong> and exact Hessian vector products. Since the method is not closely related to large sample statistical theory, I will not go deeper into the <strong>Lanczos iteration</strong> here. See Python module <a href="https://github.com/gknilsen/pydeepdelta" target="_blank" rel="noopener"><code>pydeepdelta</code></a> for more details.</p>
<h4 id="delta-method-prediction-phase">Delta Method Prediction Phase</h4>
<p>This second phase is carried out hand in hand with the regular neural network prediction process (2), and is used to approximate the associated prediction uncertainty governed by (7). This phase is based on the indirect covariance matrix approximation found in the <strong>Delta Method Initial Phase</strong>.</p>
<p>Using the typical deep learning <strong>Hessian eigenvalue spectrum</strong>, the paper proposes a partitioning of the Hessian eigendecomposition which reveals that an approximation of the positive curvature subspace of the covariance matrix can be obtained without explicitly requiring to compute any of the <span class="math inline">\(P-K\)</span> Hessian eigenvectors and eigenvalues in the midpoint gap of the spectrum, where <span class="math inline">\(P\)</span> is the number of model parameters and <span class="math inline">\(K\)</span> is the number of utilized Hessian eigenpairs. I will not go deeper into the <strong>Hessian eigenvalue spectrum</strong> but focus on the approximation steps. See <a href="#spectrum">Figure 2</a> for an example of the spectrum.</p>
<div id="spectrum">
<center>
Figure 2: A log-scale eigenvalue magnitude spectrum showing the first K/2 Hessian eigenvalues from each end of the full spectrum
</center>
</div>
<p><img src="/images/Delta-Method-in-Deep-Learning/spectrum.jpg" /></p>
<p>The full eigendecomposition of the Hessian matrix is deﬁned by <span class="math display">\[
H(\hat{\omega})=Q \Lambda Q^{T} \in \mathbb{R}^{P \times P} \tag{10}
\]</span> where <span class="math inline">\(Q \in \mathbb{R}^{P \times P}\)</span> is the matrix whose <span class="math inline">\(k\)</span>th column is the eigenvector <span class="math inline">\(q_k\)</span> of <span class="math inline">\(H(\hat{\omega})\)</span>, and <span class="math inline">\(\Lambda\in \mathbb{R}^{P \times P}\)</span> is the diagonal matrix whose diagonal elements are the corresponding eigenvalues, <span class="math inline">\(\Lambda_{kk} = \lambda_k\)</span>, assuming that the eigenvalues are sorted so that <span class="math inline">\(\lambda_1 \geq \lambda_2 \geq ... \geq \lambda_P\)</span>. The eigendecomposition of the Hessian matrix can be partitioned as follows, <span class="math display">\[
\begin{aligned}
H(\hat{\omega})=&amp; H_{\mathrm{pos}}+H_{\mathrm{gap}}+H_{\mathrm{neg}} \in \mathbb{R}^{P \times P} \\
=&amp; Q_{\mathrm{pos}} \Lambda_{\mathrm{pos}} Q_{\mathrm{pos}}^{T}+Q_{\mathrm{gap}} \Lambda_{\mathrm{gap}} Q_{\mathrm{gap}}^{T} +Q_{\mathrm{neg}} \Lambda_{\mathrm{ncg}} Q_{\mathrm{neg}}^{T}
\end{aligned} \tag{11}
\]</span> where the subscripts ‘pos’, ‘gap’ and ‘neg’ are related to the spectrum. Ignoring the principal directions in the cost landscape of negative curvature (if any) by dropping the last term in the right hand side of (11) and assuming that <span class="math inline">\(\lambda_{\frac{K}{2}} \approx \lambda_{P-\frac{K}{2}} \approx \lambda\)</span>, the covariance matrix (8) can be approximated by <span class="math inline">\(\widetilde{\Sigma}\)</span> where <span class="math display">\[
\widetilde{\Sigma} \pm \Delta^{2}=\frac{1}{N}\left[Q_{\mathrm{pos}} \Lambda_{\mathrm{pos}}^{-1} Q_{\mathrm{pos}}^{T}+\left(\lambda_{\mathrm{gap}} \pm \lambda_{\epsilon}\right)^{-1} Q_{\mathrm{gap}} Q_{\mathrm{gap}}^{T}\right] \tag{12}
\]</span> where <span class="math display">\[
\lambda_{\mathrm{gap}} \pm \lambda_{\epsilon}=\frac{\lambda_{\frac{\kappa}{2}}+\lambda_{P-\frac{K}{2}}}{2} \pm \frac{\lambda_{\frac{K}{2}}-\lambda_{P-\frac{K}{2}}}{2} \in \mathbb{R} \tag{13}
\]</span> The final form of the prediction variance approximation can be given by, <span class="math display">\[
\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right) \pm \delta^{2}=\operatorname{diag}\left\{F\left[\widetilde{\Sigma} \pm \Delta^{2}\right] F^{T}\right\} \in \mathbb{R}^{T_{L}} \tag{14}
\]</span> where the associated error <span class="math inline">\(\sigma^2\)</span> is given by, <span class="math display">\[
\delta^{2}=\frac{\lambda_{P-\frac{\kappa}{2}}^{-1}-\lambda_{\frac{K}{2}}^{-1}}{2 N} \operatorname{diag}\left\{F Q_{\mathrm{gap}} Q_{\mathrm{gap}}^{T} F^{T}\right\} \in \mathbb{R}^{T_{L}} \tag{15}
\]</span></p>
<p>Based on the above results, people can approximate the positive curvature subspace of the covariance matrix (8), and apply it to efficiently compute an approximation of (7). Finally, the approximate prediction uncertainty is given by, <span class="math display">\[
\widetilde{\sigma}\left(x_{0}, \hat{\omega}\right) \pm \epsilon^{2}=\sqrt{\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right) \pm \delta^{2}} \in \mathbb{R}^{T_{L}} \tag{16}
\]</span> with the corresponding error <span class="math inline">\(\epsilon^2\)</span> given by, <span class="math display">\[
\epsilon^{2}=\frac{1}{2}\left(\sqrt{\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right)+\delta^{2}}-\sqrt{\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right)-\delta^{2}}\right) \tag{17}
\]</span></p>
##
<center>
Summary
</center>
<hr />
<p>The paper explored the classical Delta method in a deep learning classification context. By an approximation of the positive curvature subspace of the Hessian matrix, the paper shows that reasonable uncertainty approximations can be obtained even when the number of utilized Hessian eigenpairs is much lower than the number of model parameters. This result is promising since the sheer size of the Hessian matrix seems to be the main reason why the Delta method has not received much attention in deep learning.</p>
<p>Here are some observed results that can be found in the original paper (I didn't mention them before since they are not theoretical):</p>
<ol type="1">
<li>The writers observed that prediction uncertainty in the classification context provides supplementing information to the traditional measure of probability. In particular, false positives seem to have a higher prediction uncertainty than true positives. Interestingly, this suggests that uncertainty quantification can be used to distinguish true positives from false positives.</li>
<li>They also observed that uncertainty approximation based only on the output layer is surprisingly well correlated with full model approximations. This result is important because the computational burden to compute the Hessian eigendecomposition of a model’s output layer will generally be orders of magnitude lower compared to a full model. However, more research is required to conclude that this result holds for all models and all datasets.</li>
</ol>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>Author：<a href="https://lingfengzhu.github.io">Lingfeng Zhu</a>
            <p>Original Link：<a href="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/">https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/</a> 
            <p>Published：<a href="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/">April 26th 2020, 3:19:17 pm</a>
            <p>Updated：<a href="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/">September 18th 2021, 2:47:05 pm</a>
            <p>Copyright：This Article Uses <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">Attribution-NonCommercial 4.0 International</a> as the license</p> 
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2020/06/29/BinarySearch/" title= "Binary Search">
                    <div class="nextTitle">Binary Search</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2020/04/18/BackTrack/" title= "Backtracking">
                    <div class="prevTitle">Backtracking</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- gitalk评论 -->

    <!-- utteranc评论 -->

    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:jolin.windy072@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/LingfengZhu" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
            
                <span class="iconfont-archer wechat" title=wechat>
                  
                  <img class="profile-qr" src="/assets/wechatQR.jpeg" />
                </span>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="//www.facebook.com/lingfeng.zhu.18/" class="iconfont-archer facebook" target="_blank" title=facebook></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="//www.linkedin.com/in/lingfeng-zhu-256315193/" class="iconfont-archer linkedin" target="_blank" title=linkedin></a>
            
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="about">Powered by <a href="https://lingfengzhu.github.io/about/" target="_blank">Vinn</a></span><span class="iconfont-archer power">&#xe635;</span><span id="instituion-info">from <a href="https://www.wisc.edu/" target="_blank">UWM</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
        <!-- toc -->
        
        <div class="toc-wrapper" style=
        







top:50vh;

        >
            <div class="toc-catalog">
                <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
            </div>
            
                <div id="toc-div">
            
                
                <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#the-architecture"><span class="toc-number">1.</span> <span class="toc-text">The Architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-model-function"><span class="toc-number">2.</span> <span class="toc-text">The Model Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-cost-function"><span class="toc-number">3.</span> <span class="toc-text">The Cost Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#train"><span class="toc-number">4.</span> <span class="toc-text">Train</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-delta-method"><span class="toc-number">5.</span> <span class="toc-text">The Delta Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#problems-in-application"><span class="toc-number">6.</span> <span class="toc-text">Problems in Application</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#solving-the-problems"><span class="toc-number">7.</span> <span class="toc-text">Solving the Problems</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#delta-method-initial-phase"><span class="toc-number">7.1.</span> <span class="toc-text">Delta Method Initial Phase</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#delta-method-prediction-phase"><span class="toc-number">7.2.</span> <span class="toc-text">Delta Method Prediction Phase</span></a></li></ol></li></ol>
                
            </div>
        </div>
        
        <div class="back-top iconfont-archer">&#xe639;</div> 
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 23
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2021 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/16</span><a class="archive-post-title" href= "/2021/09/16/Super/" >Super</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/10</span><a class="archive-post-title" href= "/2021/09/10/TeachersDay/" >Happy Teacher's Day</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/09</span><a class="archive-post-title" href= "/2021/09/09/CAPM/" >CAPM</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/06</span><a class="archive-post-title" href= "/2021/09/06/ERNIE/" >ERNIE</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/03</span><a class="archive-post-title" href= "/2021/09/03/Two-Pointer/" >Two-Pointer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/30</span><a class="archive-post-title" href= "/2021/08/30/Federated-Learning/" >Federated Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/27</span><a class="archive-post-title" href= "/2021/08/27/Transfer-Learning/" >Transfer Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/29</span><a class="archive-post-title" href= "/2021/07/29/Decorator/" >Python Decorator</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/29</span><a class="archive-post-title" href= "/2021/07/29/Python-args-and-kwargs/" >Python Syntax: *args and **kwargs</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/05</span><a class="archive-post-title" href= "/2021/07/05/Python-Logging/" >Python Logging</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/25</span><a class="archive-post-title" href= "/2021/05/25/BERT/" >BERT</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/08</span><a class="archive-post-title" href= "/2021/05/08/Conda/" >Conda</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/05</span><a class="archive-post-title" href= "/2021/02/05/Docker/" >Docker</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/06</span><a class="archive-post-title" href= "/2021/01/06/Trie-Tree/" >Trie Tree</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/08</span><a class="archive-post-title" href= "/2020/12/08/Gradient-Descent/" >Gradient Descent</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/16</span><a class="archive-post-title" href= "/2020/11/16/Time-Complexity/" >Time Complexity</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/15</span><a class="archive-post-title" href= "/2020/11/15/SortAlgorithm/" >Sort Algorithm</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/29</span><a class="archive-post-title" href= "/2020/06/29/BinarySearch/" >Binary Search</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/26</span><a class="archive-post-title" href= "/2020/04/26/Delta-Method-in-Deep-Learning/" >Delta Method in Deep Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/18</span><a class="archive-post-title" href= "/2020/04/18/BackTrack/" >Backtracking</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/16</span><a class="archive-post-title" href= "/2020/04/16/Python-Syntax-with/" >Python Syntax: with</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/27</span><a class="archive-post-title" href= "/2020/03/27/COVID-Survival-Analysis/" >COVID-19 Survival Analysis</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/27</span><a class="archive-post-title" href= "/2020/03/27/Hexo-Guideline/" >Hexo Guideline</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="NLP"><span class="iconfont-archer">&#xe606;</span>NLP</span>
    
        <span class="sidebar-tag-name" data-tags="Survival Analysis"><span class="iconfont-archer">&#xe606;</span>Survival Analysis</span>
    
        <span class="sidebar-tag-name" data-tags="COVID-19"><span class="iconfont-archer">&#xe606;</span>COVID-19</span>
    
        <span class="sidebar-tag-name" data-tags="Conda"><span class="iconfont-archer">&#xe606;</span>Conda</span>
    
        <span class="sidebar-tag-name" data-tags="Python"><span class="iconfont-archer">&#xe606;</span>Python</span>
    
        <span class="sidebar-tag-name" data-tags="Docker"><span class="iconfont-archer">&#xe606;</span>Docker</span>
    
        <span class="sidebar-tag-name" data-tags="Hexo"><span class="iconfont-archer">&#xe606;</span>Hexo</span>
    
        <span class="sidebar-tag-name" data-tags="Web-Frontend"><span class="iconfont-archer">&#xe606;</span>Web-Frontend</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Deep-Learning"><span class="iconfont-archer">&#xe60a;</span>Deep-Learning</span>
    
        <span class="sidebar-category-name" data-categories="Algorithm"><span class="iconfont-archer">&#xe60a;</span>Algorithm</span>
    
        <span class="sidebar-category-name" data-categories="Finance"><span class="iconfont-archer">&#xe60a;</span>Finance</span>
    
        <span class="sidebar-category-name" data-categories="Statistics"><span class="iconfont-archer">&#xe60a;</span>Statistics</span>
    
        <span class="sidebar-category-name" data-categories="Syntax"><span class="iconfont-archer">&#xe60a;</span>Syntax</span>
    
        <span class="sidebar-category-name" data-categories="Greeting"><span class="iconfont-archer">&#xe60a;</span>Greeting</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "Lingfeng Zhu"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->    
     
    </body>
</html>



<!DOCTYPE html>
<html lang="en">
    <!-- title -->




<!-- keywords -->




<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="Lingfeng Zhu">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Lingfeng Zhu">
    
    <meta name="keywords" content="machine learning,deep learning,recommender system">
    
    <meta name="description" content="">
    <meta name="description" content="This article is the Final project for STAT 732. I summarized the major results and main contributions of a recent statistical paper (published 2019) named On the Delta Method for Uncertainty Appr">
<meta property="og:type" content="article">
<meta property="og:title" content="Delta Method in Deep Learning">
<meta property="og:url" content="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/index.html">
<meta property="og:site_name" content="Vinn&#39;s Studio">
<meta property="og:description" content="This article is the Final project for STAT 732. I summarized the major results and main contributions of a recent statistical paper (published 2019) named On the Delta Method for Uncertainty Appr">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/flow.jpg">
<meta property="og:image" content="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/spectrum.jpg">
<meta property="article:published_time" content="2020-04-26T07:19:17.000Z">
<meta property="article:modified_time" content="2021-09-08T07:59:33.212Z">
<meta property="article:author" content="Lingfeng Zhu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/flow.jpg">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    
    <title>Delta Method in Deep Learning · Vinn&#39;s Studio</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/assets/favicon.ico" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

    
        <body class="post-body">
    
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >Vinn&#39;s Studio</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Delta Method in Deep Learning</a>
            </div>
    </div>
    
    <a class="home-link" href=/>Vinn's Studio</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(https://source.unsplash.com/random)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Delta Method in Deep Learning
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">1.8k</span>Reading time: <span class="post-count reading-time">11 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2020/04/26</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <script type="text/javascript"
  src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<link rel="dns-prefetch" href="//cdn.bootcss.com" />

<p>This article is the Final project for STAT 732. I summarized the major results and main contributions of a recent statistical <a href="https://arxiv.org/abs/1912.00832" target="_blank" rel="noopener">paper</a> (published 2019) named <strong>On the Delta Method for Uncertainty Approximation in Deep Learning</strong>, which utilizes large sample statistical theory in deep learning field and has significant future research potential. </p>
<a id="more"></a>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a><center>Introduction</center></h2><hr>
<p>This paper proposes a low cost approximation to the well-known Delta method based on an approximate eigendecomposition of the positive curvature subspace of the Hessian matrix and shows that reasonable uncertainty approximations can be obtained even when the number of utilized Hessian eigenpairs is much lower than the number of model parameters.</p>
<h2 id="Deep-Learning-Definitions"><a href="#Deep-Learning-Definitions" class="headerlink" title="Deep Learning Definitions"></a><center>Deep Learning Definitions</center></h2><hr>
<h3 id="The-Architecture"><a href="#The-Architecture" class="headerlink" title="The Architecture"></a>The Architecture</h3><p>The paper uses a feed-forward neural network architecture with dense layers to introduce terminology. There are $L$ layers $l = 1,2,…,L$ with $T_l$ neurons in each layer. The input layer $l = 1$, is represented by the input vector $x_n=(x_{n,1}, x_{n,2},…,x_{n,T_1})^T$ where $n = 1,2,…,N$ is the input index. Each layer $l$ represented by weight matrices $W^{(l-1)} \in \mathbb{R}^{T_{l} \times T_{l-1}}$, bias vectors $b^{(l)} \in \mathbb{R}^{T_{l}}$ and vectorized activation functions $\delta^{(l)}$. The parameter vectors representing the layer-wise weights and biases can be defined as follows,</p>
<script type="math/tex; mode=display">
\omega^{(l)}=\left[\begin{array}{c}
\text { flatten }\left(W^{(l)}\right) \\
b^{(l)}
\end{array}\right]=\left[\omega_{i}^{(l)}\right] \in \mathbb{R}^{P^{(l)}} \tag{1}</script><p>where $P^{(l)}$ denotes the number of parameters in layer $l$.</p>
<h3 id="The-Model-Function"><a href="#The-Model-Function" class="headerlink" title="The Model Function"></a>The Model Function</h3><p>The architecture has the corresponding model function defined by,</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{y}_{n}=& f\left(x_{n}, \omega\right) 
= \sigma^{(L)}\left(W^{(L)} \sigma^{(L-1)}\left(\cdots \sigma^{(2)}\left(W^{(2)} x_{n}\right.\right.\right.
&\left.\left.\left.+b^{(2)}\right)+\cdots\right)+b^{(L)}\right)
\end{aligned} \tag{2}</script><h3 id="The-Cost-Function"><a href="#The-Cost-Function" class="headerlink" title="The Cost Function"></a>The Cost Function</h3><p>Use softmax cross-entropy with $L_2$-regularization as the cost function,</p>
<script type="math/tex; mode=display">
\begin{aligned}
C(\omega) &=\frac{1}{N} \sum_{n=1}^{N} C_{n}\left(y_{n}, \hat{y}_{n}\right)+\frac{\lambda}{2} \sum_{p=1}^{P} \omega_{p}^{2} \\
&=\frac{1}{N} \sum_{n=1}^{N}\left(-\sum_{m=1}^{T_{L}} y_{n, m} \log \hat{y}_{n, m}\right)+\frac{\lambda}{2} \sum_{p=1}^{P} \omega_{p}^{2}
\end{aligned} \tag{3}</script><p>which is the average of $N$ per-example cross-entropy cost functions $C_{n}\left(y_{n}, \hat{y}_{n}\right)$.</p>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>Training of the neural network can be defined as finding an ‘optimal’ parameter vector $\hat{\omega}$ by minimizing the cost function (3).</p>
<h2 id="Delta-Method-in-Deep-Learning"><a href="#Delta-Method-in-Deep-Learning" class="headerlink" title="Delta Method in Deep Learning"></a><center>Delta Method in Deep Learning</center></h2><hr>
<h3 id="The-Delta-Method"><a href="#The-Delta-Method" class="headerlink" title="The Delta Method"></a>The Delta Method</h3><p>The Delta method views a neural network as non-linear regression. By a second-order Taylor expansion, it can be shown that the covariance of the model function (2) can be approximated by,</p>
<script type="math/tex; mode=display">
\operatorname{Cov}\left(f\left(x_{0}, \hat{\omega}\right)\right) \approx F \Sigma F^{T} \in \mathbb{R}^{T_{L} \times T_{L}} \tag{4}</script><p>where</p>
<script type="math/tex; mode=display">
F=\left[F_{i j}\right] \in \mathbb{R}^{T_{L} \times P}, F_{i j}=\left.\frac{\partial}{\partial \omega_{j}} f_{i}\left(x_{0}, \omega\right)\right|_{\omega=\hat{\omega}} \tag{5}</script><p>is the Jacobian matrix of the model function, and $\Sigma$ is the covariance matrix of the model parameters. An approximation of the variance associated with the prediction of $x_0$ can thus be found by the formula,</p>
<script type="math/tex; mode=display">
\sigma^{2}\left(x_{0}, \hat{\omega}\right) \approx \operatorname{diag}\left(F \Sigma F^{T}\right) \in \mathbb{R}^{T_{L}} \tag{6}</script><p>Furthermore, the approximate prediction uncertainty (standard deviation) associated with $x_0$ is defined as </p>
<script type="math/tex; mode=display">
\sigma\left(x_{0}, \hat{\omega}\right)=\sqrt{\sigma^{2}\left(x_{0}, \hat{\omega}\right)} \in \mathbb{R}^{T_{L}} \tag{7}</script><p>If and only if the parameter vector is a local minimum of the cost function (3), the covariance matrix of the model parameters can be estimated by the Hessian estimator,</p>
<script type="math/tex; mode=display">
\Sigma=\frac{1}{N} H(\hat{\omega})^{-1} \in \mathbb{R}^{P \times P} \tag{8}</script><p>where $H(\hat{\omega}) \in \mathbb{R}^{P \times P}$ is the Hessian matrix defined by</p>
<script type="math/tex; mode=display">
\left.H(\hat{\omega}) \stackrel{\text { def }}{=} \frac{\partial^{2} C(\omega)}{\partial \omega \partial \omega^{T}}\right|_{\omega=\hat{\omega}}=\left.\frac{1}{N} \sum_{n=1}^{N} \frac{\partial^{2} C_{n}}{\partial \omega \partial \omega^{T}}\right|_{\omega=\hat{\omega}}+\lambda I \tag{9}</script><h3 id="Problems-in-Application"><a href="#Problems-in-Application" class="headerlink" title="Problems in Application"></a>Problems in Application</h3><p>At this point, we can see that two fundamental difficulties arise when applying the Delta method in deep learning.</p>
<ul>
<li><strong>Problem 1</strong>: The sheer size of the Hessian matrix grows quadratically with $P$.</li>
<li><strong>Problem 2</strong>: For the inverse of the Hessian matrix to be a valid covariance estimator, the Hessian matrix must be positive definite. That is, we are dependent on that the optimizer can find a true local minimum of the cost function.</li>
</ul>
<h3 id="Solving-the-Problems"><a href="#Solving-the-Problems" class="headerlink" title="Solving the Problems"></a>Solving the Problems</h3><p>The paper presents its approach to the Delta method in deep learning as a separate process carried out in <strong>two phases</strong> after the neural network has been trained. See <a href="#flow">Figure 1</a> for details.</p>
<div id="flow"><center>Figure 1: The Delta method for quantifying the uncertainty in deep learning </center></div>

<img src="/2020/04/26/Delta-Method-in-Deep-Learning/flow.jpg" class="" title="This is an image">
<h4 id="Delta-Method-Initial-Phase"><a href="#Delta-Method-Initial-Phase" class="headerlink" title="Delta Method Initial Phase"></a>Delta Method Initial Phase</h4><p>This phase is carried out only once, and is done to compute an indirect approximation of the covariance matrix (8) based on an approximate eigendecomposition of the positive curvature subspace of the Hessian matrix. </p>
<p>In this phase, people can efficiently compute eigenvalues and eigenvectors of the Hessian matrix via the <strong>Lanczos iteration</strong> and exact Hessian vector products. Since the method is not closely related to large sample statistical theory, I will not go deeper into the <strong>Lanczos iteration</strong> here. See  Python module <a href="https://github.com/gknilsen/pydeepdelta" target="_blank" rel="noopener"><code>pydeepdelta</code></a> for more details.</p>
<h4 id="Delta-Method-Prediction-Phase"><a href="#Delta-Method-Prediction-Phase" class="headerlink" title="Delta Method Prediction Phase"></a>Delta Method Prediction Phase</h4><p>This second phase is carried out hand in hand with the regular neural network prediction process (2), and is used to approximate the associated prediction uncertainty governed by (7). This phase is based on the indirect covariance matrix approximation found in the <strong>Delta Method Initial Phase</strong>.</p>
<p>Using the typical deep learning <strong>Hessian eigenvalue spectrum</strong>, the paper proposes a partitioning of the Hessian eigendecomposition which reveals that an approximation of the positive curvature subspace of the covariance matrix can be obtained without explicitly requiring to compute any of the $P-K$ Hessian eigenvectors and eigenvalues in the midpoint gap of the spectrum, where $P$ is the number of model parameters and $K$ is the number of utilized Hessian eigenpairs. I will not go deeper into the <strong>Hessian eigenvalue spectrum</strong> but focus on the approximation steps. See <a href="#spectrum">Figure 2</a> for an example of the spectrum.</p>
<div id="spectrum"><center>Figure 2: A log-scale eigenvalue magnitude spectrum showing the first K/2 Hessian eigenvalues from each end of the full spectrum</center></div>

<img src="/2020/04/26/Delta-Method-in-Deep-Learning/spectrum.jpg" class="" title="This is an image">
<p>The full eigendecomposition of the Hessian matrix is deﬁned by</p>
<script type="math/tex; mode=display">
H(\hat{\omega})=Q \Lambda Q^{T} \in \mathbb{R}^{P \times P} \tag{10}</script><p>where $Q \in \mathbb{R}^{P \times P}$ is the matrix whose $k$th column is the eigenvector $q_k$ of $H(\hat{\omega})$, and $\Lambda\in \mathbb{R}^{P \times P}$ is the diagonal matrix whose diagonal elements are the corresponding eigenvalues, $\Lambda_{kk} = \lambda_k$, assuming that the eigenvalues are sorted so that $\lambda_1 \geq \lambda_2 \geq … \geq \lambda_P$.<br>The eigendecomposition of the Hessian matrix can be partitioned as follows,</p>
<script type="math/tex; mode=display">
\begin{aligned}
H(\hat{\omega})=& H_{\mathrm{pos}}+H_{\mathrm{gap}}+H_{\mathrm{neg}} \in \mathbb{R}^{P \times P} \\
=& Q_{\mathrm{pos}} \Lambda_{\mathrm{pos}} Q_{\mathrm{pos}}^{T}+Q_{\mathrm{gap}} \Lambda_{\mathrm{gap}} Q_{\mathrm{gap}}^{T} +Q_{\mathrm{neg}} \Lambda_{\mathrm{ncg}} Q_{\mathrm{neg}}^{T}
\end{aligned} \tag{11}</script><p>where the subscripts ‘pos’, ‘gap’ and ‘neg’ are related to the spectrum. Ignoring the principal directions in the cost landscape of negative curvature (if any) by dropping the last term in the right hand side of (11) and assuming that $\lambda_{\frac{K}{2}} \approx \lambda_{P-\frac{K}{2}} \approx \lambda$, the covariance matrix (8) can be approximated by $\widetilde{\Sigma}$ where</p>
<script type="math/tex; mode=display">
\widetilde{\Sigma} \pm \Delta^{2}=\frac{1}{N}\left[Q_{\mathrm{pos}} \Lambda_{\mathrm{pos}}^{-1} Q_{\mathrm{pos}}^{T}+\left(\lambda_{\mathrm{gap}} \pm \lambda_{\epsilon}\right)^{-1} Q_{\mathrm{gap}} Q_{\mathrm{gap}}^{T}\right] \tag{12}</script><p>where</p>
<script type="math/tex; mode=display">
\lambda_{\mathrm{gap}} \pm \lambda_{\epsilon}=\frac{\lambda_{\frac{\kappa}{2}}+\lambda_{P-\frac{K}{2}}}{2} \pm \frac{\lambda_{\frac{K}{2}}-\lambda_{P-\frac{K}{2}}}{2} \in \mathbb{R} \tag{13}</script><p>The final form of the prediction variance approximation can be given by,</p>
<script type="math/tex; mode=display">
\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right) \pm \delta^{2}=\operatorname{diag}\left\{F\left[\widetilde{\Sigma} \pm \Delta^{2}\right] F^{T}\right\} \in \mathbb{R}^{T_{L}} \tag{14}</script><p>where the associated error $\sigma^2$ is given by,</p>
<script type="math/tex; mode=display">
\delta^{2}=\frac{\lambda_{P-\frac{\kappa}{2}}^{-1}-\lambda_{\frac{K}{2}}^{-1}}{2 N} \operatorname{diag}\left\{F Q_{\mathrm{gap}} Q_{\mathrm{gap}}^{T} F^{T}\right\} \in \mathbb{R}^{T_{L}} \tag{15}</script><p>Based on the above results, people can approximate the positive curvature subspace of the covariance matrix (8), and apply it to efficiently compute an approximation of (7). Finally, the approximate prediction uncertainty is given by,</p>
<script type="math/tex; mode=display">
\widetilde{\sigma}\left(x_{0}, \hat{\omega}\right) \pm \epsilon^{2}=\sqrt{\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right) \pm \delta^{2}} \in \mathbb{R}^{T_{L}} \tag{16}</script><p>with the corresponding error $\epsilon^2$ given by,</p>
<script type="math/tex; mode=display">
\epsilon^{2}=\frac{1}{2}\left(\sqrt{\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right)+\delta^{2}}-\sqrt{\widetilde{\sigma^{2}}\left(x_{0}, \hat{\omega}\right)-\delta^{2}}\right) \tag{17}</script><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><center>Summary</center></h2><hr>
<p>The paper explored the classical Delta method in a deep learning classification context. By an approximation of the positive curvature subspace of the Hessian matrix, the paper shows that reasonable uncertainty approximations can be obtained even when the number of utilized Hessian eigenpairs is much lower than the number of model parameters. This result is promising since the sheer size of the Hessian matrix seems to be the main reason why the Delta method has not received much attention in deep learning. </p>
<p>Here are some observed results that can be found in the original paper (I didn’t mention them before since they are not theoretical):</p>
<ol>
<li>The writers observed that prediction uncertainty in the classification context provides supplementing information to the traditional measure of probability. In particular, false positives seem to have a higher prediction uncertainty than true positives. Interestingly, this suggests that uncertainty quantification can be used to distinguish true positives from false positives.</li>
<li>They also observed that uncertainty approximation based only on the output layer is surprisingly well correlated with full model approximations. This result is important because the computational burden to compute the Hessian eigendecomposition of a model’s output layer will generally be orders of magnitude lower compared to a full model. However, more research is required to conclude that this result holds for all models and all datasets.</li>
</ol>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>Author：<a href="https://lingfengzhu.github.io">Lingfeng Zhu</a>
            <p>Original Link：<a href="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/">https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/</a> 
            <p>Published：<a href="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/">April 26th 2020, 3:19:17 pm</a>
            <p>Updated：<a href="https://lingfengzhu.github.io/2020/04/26/Delta-Method-in-Deep-Learning/">September 8th 2021, 3:59:33 pm</a>
            <p>Copyright：This Article Uses <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">Attribution-NonCommercial 4.0 International</a> as the license</p> 
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2020/06/29/BinarySearch/" title= "Binary Search">
                    <div class="nextTitle">Binary Search</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2020/04/18/BackTrack/" title= "Backtracking">
                    <div class="prevTitle">Backtracking</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- gitalk评论 -->

    <!-- utteranc评论 -->

    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:jolin.windy072@gmail.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/LingfengZhu" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
            
                <span class="iconfont-archer wechat" title=wechat>
                  
                  <img class="profile-qr" src="/assets/wechatQR.jpeg" />
                </span>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="//www.facebook.com/lingfeng.zhu.18/" class="iconfont-archer facebook" target="_blank" title=facebook></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="//www.linkedin.com/in/lingfeng-zhu-256315193/" class="iconfont-archer linkedin" target="_blank" title=linkedin></a>
            
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="about">Powered by <a href="https://lingfengzhu.github.io/about/" target="_blank">Vinn</a></span><span class="iconfont-archer power">&#xe635;</span><span id="instituion-info">from <a href="https://www.wisc.edu/" target="_blank">UWM</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Learning-Definitions"><span class="toc-number">2.</span> <span class="toc-text">Deep Learning Definitions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Architecture"><span class="toc-number">2.1.</span> <span class="toc-text">The Architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Model-Function"><span class="toc-number">2.2.</span> <span class="toc-text">The Model Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Cost-Function"><span class="toc-number">2.3.</span> <span class="toc-text">The Cost Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Train"><span class="toc-number">2.4.</span> <span class="toc-text">Train</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Delta-Method-in-Deep-Learning"><span class="toc-number">3.</span> <span class="toc-text">Delta Method in Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Delta-Method"><span class="toc-number">3.1.</span> <span class="toc-text">The Delta Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problems-in-Application"><span class="toc-number">3.2.</span> <span class="toc-text">Problems in Application</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Solving-the-Problems"><span class="toc-number">3.3.</span> <span class="toc-text">Solving the Problems</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Delta-Method-Initial-Phase"><span class="toc-number">3.3.1.</span> <span class="toc-text">Delta Method Initial Phase</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Delta-Method-Prediction-Phase"><span class="toc-number">3.3.2.</span> <span class="toc-text">Delta Method Prediction Phase</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-number">4.</span> <span class="toc-text">Summary</span></a></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 22
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2021 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/10</span><a class="archive-post-title" href= "/2021/09/10/TeachersDay/" >TeachersDay</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/09</span><a class="archive-post-title" href= "/2021/09/09/CAPM/" >CAPM</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/06</span><a class="archive-post-title" href= "/2021/09/06/ERNIE/" >ERNIE</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/03</span><a class="archive-post-title" href= "/2021/09/03/Two-Pointer/" >Two-Pointer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/30</span><a class="archive-post-title" href= "/2021/08/30/Federated-Learning/" >Federated Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/27</span><a class="archive-post-title" href= "/2021/08/27/Transfer-Learning/" >Transfer Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/29</span><a class="archive-post-title" href= "/2021/07/29/Decorator/" >Python Decorator</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/29</span><a class="archive-post-title" href= "/2021/07/29/Python-args-and-kwargs/" >Python Syntax: *args and **kwargs</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/05</span><a class="archive-post-title" href= "/2021/07/05/Python-Logging/" >Python Logging</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/25</span><a class="archive-post-title" href= "/2021/05/25/BERT/" >BERT</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/08</span><a class="archive-post-title" href= "/2021/05/08/Conda/" >Conda</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/05</span><a class="archive-post-title" href= "/2021/02/05/Docker/" >Docker</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/06</span><a class="archive-post-title" href= "/2021/01/06/Trie-Tree/" >Trie Tree</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">12/08</span><a class="archive-post-title" href= "/2020/12/08/Gradient-Descent/" >Gradient Descent</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/16</span><a class="archive-post-title" href= "/2020/11/16/Time-Complexity/" >Time Complexity</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">11/15</span><a class="archive-post-title" href= "/2020/11/15/SortAlgorithm/" >Sort Algorithm</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/29</span><a class="archive-post-title" href= "/2020/06/29/BinarySearch/" >Binary Search</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/26</span><a class="archive-post-title" href= "/2020/04/26/Delta-Method-in-Deep-Learning/" >Delta Method in Deep Learning</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/18</span><a class="archive-post-title" href= "/2020/04/18/BackTrack/" >Backtracking</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/16</span><a class="archive-post-title" href= "/2020/04/16/Python-Syntax-with/" >Python Syntax: with</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/27</span><a class="archive-post-title" href= "/2020/03/27/COVID-Survival-Anaysis/" >COVID-19 Survival Analysis</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/27</span><a class="archive-post-title" href= "/2020/03/27/Hexo-Guideline/" >Hexo Guideline</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="NLP"><span class="iconfont-archer">&#xe606;</span>NLP</span>
    
        <span class="sidebar-tag-name" data-tags="Survival Analysis"><span class="iconfont-archer">&#xe606;</span>Survival Analysis</span>
    
        <span class="sidebar-tag-name" data-tags="COVID-19"><span class="iconfont-archer">&#xe606;</span>COVID-19</span>
    
        <span class="sidebar-tag-name" data-tags="Conda"><span class="iconfont-archer">&#xe606;</span>Conda</span>
    
        <span class="sidebar-tag-name" data-tags="Docker"><span class="iconfont-archer">&#xe606;</span>Docker</span>
    
        <span class="sidebar-tag-name" data-tags="Python"><span class="iconfont-archer">&#xe606;</span>Python</span>
    
        <span class="sidebar-tag-name" data-tags="Hexo"><span class="iconfont-archer">&#xe606;</span>Hexo</span>
    
        <span class="sidebar-tag-name" data-tags="Web-Frontend"><span class="iconfont-archer">&#xe606;</span>Web-Frontend</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Deep-Learning"><span class="iconfont-archer">&#xe60a;</span>Deep-Learning</span>
    
        <span class="sidebar-category-name" data-categories="Algorithm"><span class="iconfont-archer">&#xe60a;</span>Algorithm</span>
    
        <span class="sidebar-category-name" data-categories="Finance"><span class="iconfont-archer">&#xe60a;</span>Finance</span>
    
        <span class="sidebar-category-name" data-categories="Statistics"><span class="iconfont-archer">&#xe60a;</span>Statistics</span>
    
        <span class="sidebar-category-name" data-categories="Syntax"><span class="iconfont-archer">&#xe60a;</span>Syntax</span>
    
        <span class="sidebar-category-name" data-categories="greeting"><span class="iconfont-archer">&#xe60a;</span>greeting</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "Lingfeng Zhu"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->    
     
    </body>
</html>


